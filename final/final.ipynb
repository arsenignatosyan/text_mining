{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import tqdm\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics_for_regression_sklearn(y_pred, y_true):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    single_squared_errors = ((y_pred - y_true)**2).tolist()\n",
    "\n",
    "    # Compute accuracy\n",
    "    # Based on the fact that the rounded score = true score only if |single_squared_errors| < 0.5\n",
    "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    single_squared_errors = ((logits - labels).flatten()**2).tolist()\n",
    "\n",
    "    # Compute accuracy\n",
    "    # Based on the fact that the rounded score = true score only if |single_squared_errors| < 0.5\n",
    "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data and Manipulate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-2016dev-A.tsv\n",
      "sentiment\n",
      "positive    829\n",
      "neutral     746\n",
      "negative    391\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2016test-A.tsv\n",
      "sentiment\n",
      "neutral     10342\n",
      "positive     7059\n",
      "negative     3231\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2013train-A.tsv\n",
      "sentiment\n",
      "neutral     4586\n",
      "positive    3640\n",
      "negative    1458\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2016train-A.tsv\n",
      "sentiment\n",
      "positive    3017\n",
      "neutral     2001\n",
      "negative     850\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2015test-A.tsv\n",
      "sentiment\n",
      "positive    1038\n",
      "neutral      987\n",
      "negative     365\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2015train-A.tsv\n",
      "sentiment\n",
      "neutral     253\n",
      "positive    170\n",
      "negative     66\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2013dev-A.tsv\n",
      "sentiment\n",
      "neutral     739\n",
      "positive    575\n",
      "negative    340\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2016devtest-A.tsv\n",
      "sentiment\n",
      "positive    994\n",
      "neutral     681\n",
      "negative    325\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2013test-A.tsv\n",
      "sentiment\n",
      "neutral     1513\n",
      "positive    1475\n",
      "negative     559\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2014sarcasm-A.tsv\n",
      "sentiment\n",
      "negative    22\n",
      "positive    20\n",
      "neutral      7\n",
      "Name: count, dtype: int64\n",
      "================\n",
      "twitter-2014test-A.tsv\n",
      "sentiment\n",
      "positive    982\n",
      "neutral     669\n",
      "negative    202\n",
      "Name: count, dtype: int64\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "lens = 0\n",
    "\n",
    "base_path = \"semeval-2017-tweets_Subtask-A/downloaded/\"\n",
    "base_df = pd.DataFrame()\n",
    "colnames=['id', 'sentiment', 'tweet']\n",
    "for df_path in os.listdir(base_path):\n",
    "    path = os.path.join(base_path, df_path)\n",
    "    print(df_path)\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=None)\n",
    "    if df.shape[1] > 3:\n",
    "        df = df.iloc[:, 0:3]\n",
    "    df.columns = colnames\n",
    "    print(df[\"sentiment\"].value_counts())\n",
    "    print(\"================\")\n",
    "    base_df = pd.concat([base_df, df], ignore_index=True)\n",
    "    lens += len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638060586258038784</td>\n",
       "      <td>neutral</td>\n",
       "      <td>05 Beat it - Michael Jackson - Thriller (25th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>638061181823922176</td>\n",
       "      <td>positive</td>\n",
       "      <td>Jay Z joins Instagram with nostalgic tribute t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>638083821364244480</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Michael Jackson: Bad 25th Anniversary Edition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>638091450132078593</td>\n",
       "      <td>positive</td>\n",
       "      <td>I liked a @YouTube video http://t.co/AaR3pjp2P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638125563790557184</td>\n",
       "      <td>positive</td>\n",
       "      <td>18th anniv of Princess Diana's death. I still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50127</th>\n",
       "      <td>210378118865756160</td>\n",
       "      <td>neutral</td>\n",
       "      <td>It's a Wednesday girls night out as '90's band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50128</th>\n",
       "      <td>245177521304399872</td>\n",
       "      <td>positive</td>\n",
       "      <td>night college course sorted, just have to enro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50129</th>\n",
       "      <td>259280987089932288</td>\n",
       "      <td>positive</td>\n",
       "      <td>For the 1st time in 30 years. For your splendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50130</th>\n",
       "      <td>201113950211940352</td>\n",
       "      <td>positive</td>\n",
       "      <td>NURSES DAY - 12 MAY 2012. Nursing: The heart b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50131</th>\n",
       "      <td>237999067286876160</td>\n",
       "      <td>neutral</td>\n",
       "      <td>We have 15 minutes left until the 2nd episode ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50132 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id sentiment  \\\n",
       "0      638060586258038784   neutral   \n",
       "1      638061181823922176  positive   \n",
       "2      638083821364244480   neutral   \n",
       "3      638091450132078593  positive   \n",
       "4      638125563790557184  positive   \n",
       "...                   ...       ...   \n",
       "50127  210378118865756160   neutral   \n",
       "50128  245177521304399872  positive   \n",
       "50129  259280987089932288  positive   \n",
       "50130  201113950211940352  positive   \n",
       "50131  237999067286876160   neutral   \n",
       "\n",
       "                                                   tweet  \n",
       "0      05 Beat it - Michael Jackson - Thriller (25th ...  \n",
       "1      Jay Z joins Instagram with nostalgic tribute t...  \n",
       "2      Michael Jackson: Bad 25th Anniversary Edition ...  \n",
       "3      I liked a @YouTube video http://t.co/AaR3pjp2P...  \n",
       "4      18th anniv of Princess Diana's death. I still ...  \n",
       "...                                                  ...  \n",
       "50127  It's a Wednesday girls night out as '90's band...  \n",
       "50128  night college course sorted, just have to enro...  \n",
       "50129  For the 1st time in 30 years. For your splendi...  \n",
       "50130  NURSES DAY - 12 MAY 2012. Nursing: The heart b...  \n",
       "50131  We have 15 minutes left until the 2nd episode ...  \n",
       "\n",
       "[50132 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638060586258038784</td>\n",
       "      <td>neutral</td>\n",
       "      <td>05 Beat it - Michael Jackson - Thriller (25th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>638061181823922176</td>\n",
       "      <td>positive</td>\n",
       "      <td>Jay Z joins Instagram with nostalgic tribute t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>638083821364244480</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Michael Jackson: Bad 25th Anniversary Edition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>638091450132078593</td>\n",
       "      <td>positive</td>\n",
       "      <td>I liked a @YouTube video http://t.co/AaR3pjp2P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638125563790557184</td>\n",
       "      <td>positive</td>\n",
       "      <td>18th anniv of Princess Diana's death. I still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50127</th>\n",
       "      <td>210378118865756160</td>\n",
       "      <td>neutral</td>\n",
       "      <td>It's a Wednesday girls night out as '90's band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50128</th>\n",
       "      <td>245177521304399872</td>\n",
       "      <td>positive</td>\n",
       "      <td>night college course sorted, just have to enro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50129</th>\n",
       "      <td>259280987089932288</td>\n",
       "      <td>positive</td>\n",
       "      <td>For the 1st time in 30 years. For your splendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50130</th>\n",
       "      <td>201113950211940352</td>\n",
       "      <td>positive</td>\n",
       "      <td>NURSES DAY - 12 MAY 2012. Nursing: The heart b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50131</th>\n",
       "      <td>237999067286876160</td>\n",
       "      <td>neutral</td>\n",
       "      <td>We have 15 minutes left until the 2nd episode ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49467 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id sentiment  \\\n",
       "0      638060586258038784   neutral   \n",
       "1      638061181823922176  positive   \n",
       "2      638083821364244480   neutral   \n",
       "3      638091450132078593  positive   \n",
       "4      638125563790557184  positive   \n",
       "...                   ...       ...   \n",
       "50127  210378118865756160   neutral   \n",
       "50128  245177521304399872  positive   \n",
       "50129  259280987089932288  positive   \n",
       "50130  201113950211940352  positive   \n",
       "50131  237999067286876160   neutral   \n",
       "\n",
       "                                                   tweet  \n",
       "0      05 Beat it - Michael Jackson - Thriller (25th ...  \n",
       "1      Jay Z joins Instagram with nostalgic tribute t...  \n",
       "2      Michael Jackson: Bad 25th Anniversary Edition ...  \n",
       "3      I liked a @YouTube video http://t.co/AaR3pjp2P...  \n",
       "4      18th anniv of Princess Diana's death. I still ...  \n",
       "...                                                  ...  \n",
       "50127  It's a Wednesday girls night out as '90's band...  \n",
       "50128  night college course sorted, just have to enro...  \n",
       "50129  For the 1st time in 30 years. For your splendi...  \n",
       "50130  NURSES DAY - 12 MAY 2012. Nursing: The heart b...  \n",
       "50131  We have 15 minutes left until the 2nd episode ...  \n",
       "\n",
       "[49467 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = base_df[\"tweet\"]\n",
    "y = base_df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     22182\n",
       "positive    19572\n",
       "negative     7713\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, stratify=y_train_val, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31658, 7915, 9894)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = y_train.map({\"negative\": 0, \"neutral\": 1, \"positive\":2})\n",
    "y_val = y_val.map({\"negative\": 0, \"neutral\": 1, \"positive\":2})\n",
    "y_test = y_test.map({\"negative\": 0, \"neutral\": 1, \"positive\":2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words=\"english\", lowercase=True, ngram_range=(1, 3), analyzer=\"word\")\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_val_counts = count_vect.transform(X_val)\n",
    "X_test_counts = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(X_train_counts)\n",
    "X_train_tfidf = tfidf_transformer.transform(X_train_counts)\n",
    "X_val_tfidf = tfidf_transformer.transform(X_val_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_val_pred_svr = svr.predict(X_val_tfidf)\n",
    "r2_score(y_val, y_val_pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compute_metrics_for_regression_sklearn(y_val_pred_svr, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fine-tuning Standard Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_train, \"label\": y_train}))\n",
    "# val_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_val, \"label\": y_val}))\n",
    "# test_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_test, \"label\": y_test}))\n",
    "class SemevalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL = \"distilbert-base-uncased\"\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 20\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train.values.tolist(), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(X_val.values.tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test.values.tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SemevalDataset(train_encodings, y_train.values.tolist())\n",
    "val_dataset = SemevalDataset(val_encodings, y_val.values.tolist())\n",
    "test_dataset = SemevalDataset(test_encodings, y_test.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# ds = {\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds}\n",
    "\n",
    "# def preprocess_function(examples):\n",
    "#     examples = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "#     # examples[\"label\"] = float(examples[\"label\"])\n",
    "\n",
    "#     return examples\n",
    "\n",
    "# for split in ds:\n",
    "#     ds[split] = ds[split].map(preprocess_function, remove_columns=[\"__index_level_0__\", \"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"mps\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                           | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                        | 0/1979 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|                                                                                                                                                                              | 1/1979 [00:05<2:51:09,  5.19s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|â–                                                                                                                                                                             | 2/1979 [00:06<1:35:31,  2.90s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|â–Ž                                                                                                                                                                             | 3/1979 [00:07<1:08:55,  2.09s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|â–Ž                                                                                                                                                                               | 4/1979 [00:08<56:29,  1.72s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|â–                                                                                                                                                                               | 5/1979 [00:09<49:18,  1.50s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|â–                                                                                                                                                                             | 5/1979 [00:10<1:09:17,  2.11s/it]\n",
      "  0%|                                                                                                                                                                                           | 0/3 [00:10<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "device = torch.device('mps')\n",
    "model.to(device)\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in tqdm.tqdm(range(3)):\n",
    "    for batch in tqdm.tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        labels = labels.to(torch.float32)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(\"prca\")\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/bert-base-uncased\",          # output directory\n",
    "    num_train_epochs=EPOCHS,              # total number of training epochs\n",
    "    per_device_train_batch_size=4,  # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n",
    "#     warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "#     logging_steps=10,\n",
    ")\n",
    "\n",
    "# model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    "    compute_metrics=compute_metrics_for_regression,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['label', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 31658\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['label', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 7915\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['label', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 9894\n",
       " })}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./models/bert-base-uncased\",\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "#     per_device_train_batch_size=BATCH_SIZE,\n",
    "#     per_device_eval_batch_size=BATCH_SIZE,\n",
    "#     num_train_epochs=EPOCHS,\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     save_total_limit=2,\n",
    "#     metric_for_best_model=\"accuracy\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     weight_decay=0.01,\n",
    "# )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"./models/bert-base-uncased\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=2,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"epoch\",\n",
    "#    push_to_hub=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        print(len(inputs))\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        print(\"hima ste em\")\n",
    "        logits = outputs[0][:, 0]\n",
    "        loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        print(\"hasel em ste\")\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# trainer = RegressionTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=ds[\"train\"],\n",
    "#     eval_dataset=ds[\"validation\"],\n",
    "#     compute_metrics=compute_metrics_for_regression,\n",
    "#     data_collator=data_collator,\n",
    "#     tokenizer=tokenizer\n",
    "# )\n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=ds[\"train\"],\n",
    "   eval_dataset=ds[\"validation\"],\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics_for_regression,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_min",
   "language": "python",
   "name": "text_min"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}