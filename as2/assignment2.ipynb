{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05dfdbcd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1b0a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arsen/miniconda3/envs/text_min/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, \\\n",
    "                         TrainingArguments, Trainer\n",
    "from torch.optim import AdamW\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4033aa3",
   "metadata": {},
   "source": [
    "# Load and Process Dataset\n",
    "\n",
    "We start by loading the conll data via the hugging face api and its load_dataset function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dcab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"wnut_17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1535e282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3394\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1009\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1287\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10bca283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@paulwalk',\n",
       " 'It',\n",
       " \"'s\",\n",
       " 'the',\n",
       " 'view',\n",
       " 'from',\n",
       " 'where',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'living',\n",
       " 'for',\n",
       " 'two',\n",
       " 'weeks',\n",
       " '.',\n",
       " 'Empire',\n",
       " 'State',\n",
       " 'Building',\n",
       " '=',\n",
       " 'ESB',\n",
       " '.',\n",
       " 'Pretty',\n",
       " 'bad',\n",
       " 'storm',\n",
       " 'here',\n",
       " 'last',\n",
       " 'evening',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e811ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde37674",
   "metadata": {},
   "source": [
    "Followingly, we extract the named entitiy recognition features and the respective IOB labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a34c0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-corporation', 'I-corporation', 'B-creative-work', 'I-creative-work', 'B-group', 'I-group', 'B-location', 'I-location', 'B-person', 'I-person', 'B-product', 'I-product'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794bb5e",
   "metadata": {},
   "source": [
    "We see that the train body features labels about corporations, creative-work, groups, locations, perople, and products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060450fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-corporation',\n",
       " 'I-corporation',\n",
       " 'B-creative-work',\n",
       " 'I-creative-work',\n",
       " 'B-group',\n",
       " 'I-group',\n",
       " 'B-location',\n",
       " 'I-location',\n",
       " 'B-person',\n",
       " 'I-person',\n",
       " 'B-product',\n",
       " 'I-product']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c05f4f9",
   "metadata": {},
   "source": [
    "Based on this, we can express the decoded information and a respective sentence jointly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b3493d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@paulwalk It 's the view from where I 'm living for two weeks . Empire     State      Building   = ESB        . Pretty bad storm here last evening . \n",
      "O         O  O  O   O    O    O     O O  O      O   O   O     O B-location I-location I-location O B-location O O      O   O     O    O    O       O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782581a",
   "metadata": {},
   "source": [
    "We will use a pretrained bert model to evaluate the contents of the WNUT dataset. This dataset features a lot of rare entities and thereby allows for testing models on largely unseen information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9dcd5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9c37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e339a03",
   "metadata": {},
   "source": [
    "Next, we will give the tokens new labels which align with their new labels, which express their purpose numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be042439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd0ac737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5408c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05621643",
   "metadata": {},
   "source": [
    "Having composed a function to tokenise and align the labels, we finally arrive at a preprocessed and tokenised dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b26d1662",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35970fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b3a426",
   "metadata": {},
   "source": [
    "# Setting Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae3f7a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdd29742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ec27879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_token_classification(predictions, labels, entity_types):\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    precision_dict = {}\n",
    "    recall_dict = {}\n",
    "    f1_dict = {}\n",
    "    support_dict = {}\n",
    "    \n",
    "    for entity_type in entity_types:\n",
    "        precision_dict[entity_type] = {}\n",
    "        recall_dict[entity_type] = {}\n",
    "        f1_dict[entity_type] = {}\n",
    "        support_dict[entity_type] = {}\n",
    "        b_true_labels_binary = [[l if f\"B-{entity_type}\" == l else 'O' for l in label] for label in labels]\n",
    "        b_pred_labels_binary = [[l if f\"B-{entity_type}\" == l else 'O' for l in label] for label in predictions]\n",
    "        \n",
    "        b_metrics = metric.compute(predictions=b_pred_labels_binary, references=b_true_labels_binary)\n",
    "        \n",
    "        precision_dict[entity_type]['B-label'] = b_metrics[entity_type]['precision']\n",
    "        recall_dict[entity_type]['B-label'] = b_metrics[entity_type]['recall']\n",
    "        f1_dict[entity_type]['B-label'] = b_metrics[entity_type]['f1']\n",
    "        support_dict[entity_type]['B-label'] = b_metrics[entity_type]['number']\n",
    "        \n",
    "        i_true_labels_binary = [[l if f\"I-{entity_type}\" == l else 'O' for l in label] for label in labels]\n",
    "        i_pred_labels_binary = [[l if f\"I-{entity_type}\" == l else 'O' for l in label] for label in predictions]\n",
    "    \n",
    "        i_metrics = metric.compute(predictions=i_pred_labels_binary, references=i_true_labels_binary)\n",
    "        \n",
    "        precision_dict[entity_type]['I-label'] = i_metrics[entity_type]['precision']\n",
    "        recall_dict[entity_type]['I-label'] = i_metrics[entity_type]['recall']\n",
    "        f1_dict[entity_type]['I-label'] = i_metrics[entity_type]['f1']\n",
    "        support_dict[entity_type]['I-label'] = i_metrics[entity_type]['number']\n",
    "\n",
    "    entity_metrics = metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    for entity_type in entity_types:\n",
    "        precision_dict[entity_type]['entity'] = entity_metrics[entity_type]['precision']\n",
    "        recall_dict[entity_type]['entity'] = entity_metrics[entity_type]['recall']\n",
    "        f1_dict[entity_type]['entity'] = entity_metrics[entity_type]['f1']\n",
    "        support_dict[entity_type]['entity'] = entity_metrics[entity_type]['number']\n",
    "        \n",
    "    f1_scores_list = [f1_dict[entity_type][\"entity\"] for entity_type in f1_dict] \n",
    "    support_list = [support_dict[entity_type][\"entity\"] for entity_type in support_dict]\n",
    "    weights_support_list = [support / len(support_list) for support in support_list]\n",
    "    \n",
    "    final_dict = {\n",
    "        \"precision\": precision_dict,\n",
    "        \"recall\": recall_dict,\n",
    "        \"f1\": f1_dict,\n",
    "        \"macro_f1\": sum(f1_scores_list) / len(f1_scores_list),\n",
    "        \"micro_f1\": sum([f1_score * support for f1_score, support in zip(f1_scores_list, weights_support_list)])\n",
    "    }\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df648e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types = ['corporation', 'creative-work', 'group', 'location', 'person', 'product']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6b16d",
   "metadata": {},
   "source": [
    "# Fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45ebd613",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a209cf",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "\n",
    "We will use the bert model with baseline parameters for our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aad48fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1275' max='1275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1275/1275 13:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.041900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.24935071170330048,\n",
       " 'test_precision': 0.47183098591549294,\n",
       " 'test_recall': 0.31047265987025024,\n",
       " 'test_f1': 0.37451089994410286,\n",
       " 'test_accuracy': 0.9348994974874372,\n",
       " 'test_runtime': 102.8448,\n",
       " 'test_samples_per_second': 12.514,\n",
       " 'test_steps_per_second': 1.565}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_baseline = TrainingArguments(\"bert-finetuned-baseline\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "trainer_baseline = Trainer(\n",
    "    model=model,\n",
    "    args=args_baseline,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer_baseline.train()\n",
    "\n",
    "test_pred_baseline = trainer_baseline.predict(test_dataset=tokenized_datasets[\"test\"])\n",
    "test_pred_baseline.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d827381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'creative-work': {'B-label': 0.0,\n",
      "                          'I-label': 0.010256410256410256,\n",
      "                          'entity': 0.0},\n",
      "        'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'location': {'B-label': 0.030769230769230767,\n",
      "                     'I-label': 0.0,\n",
      "                     'entity': 0.007246376811594203},\n",
      "        'person': {'B-label': 0.009022556390977444,\n",
      "                   'I-label': 0.0,\n",
      "                   'entity': 0.0029112081513828236},\n",
      "        'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}},\n",
      " 'macro_f1': 0.0016929308271628378,\n",
      " 'micro_f1': 0.38931080311372696,\n",
      " 'precision': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'creative-work': {'B-label': 0.0,\n",
      "                                 'I-label': 0.015151515151515152,\n",
      "                                 'entity': 0.0},\n",
      "               'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'location': {'B-label': 0.03636363636363636,\n",
      "                            'I-label': 0.0,\n",
      "                            'entity': 0.007936507936507936},\n",
      "               'person': {'B-label': 0.012711864406779662,\n",
      "                          'I-label': 0.0,\n",
      "                          'entity': 0.003875968992248062},\n",
      "               'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}},\n",
      " 'recall': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'creative-work': {'B-label': 0.0,\n",
      "                              'I-label': 0.007751937984496124,\n",
      "                              'entity': 0.0},\n",
      "            'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'location': {'B-label': 0.02666666666666667,\n",
      "                         'I-label': 0.0,\n",
      "                         'entity': 0.006666666666666667},\n",
      "            'person': {'B-label': 0.006993006993006993,\n",
      "                       'I-label': 0.0,\n",
      "                       'entity': 0.002331002331002331},\n",
      "            'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "macro_micro_baseline = evaluate_token_classification(predictions=test_pred_baseline.predictions, \\\n",
    "                                                     labels=test_pred_baseline.label_ids, \\\n",
    "                                                     entity_types=entity_types)\n",
    "pprint(macro_micro_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5f7c9b",
   "metadata": {},
   "source": [
    "Overall, the results are rather poor. Next, we will apply different optimisation approaches to improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276bb7e",
   "metadata": {},
   "source": [
    "### AdamW Optimization\n",
    "\n",
    "We begin by implementing the AdamW optimiser, which makes use of the general Adam optimisation approach and adds L2 regularisation via a decay in the parameter weights at each iteration. By implementing weight decay, we ensure that the model is more generaliseable and performs better on unseen data. The hyperparameters are again based on a a premade bert configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1575ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1275' max='1275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1275/1275 11:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.167101</td>\n",
       "      <td>0.526126</td>\n",
       "      <td>0.349282</td>\n",
       "      <td>0.419842</td>\n",
       "      <td>0.915547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.180026</td>\n",
       "      <td>0.588138</td>\n",
       "      <td>0.427033</td>\n",
       "      <td>0.494802</td>\n",
       "      <td>0.922826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.173017</td>\n",
       "      <td>0.585227</td>\n",
       "      <td>0.492823</td>\n",
       "      <td>0.535065</td>\n",
       "      <td>0.927696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.23202502727508545,\n",
       " 'test_precision': 0.5274390243902439,\n",
       " 'test_recall': 0.3206672845227062,\n",
       " 'test_f1': 0.3988472622478386,\n",
       " 'test_accuracy': 0.9359798994974874,\n",
       " 'test_runtime': 9.4282,\n",
       " 'test_samples_per_second': 136.506,\n",
       " 'test_steps_per_second': 17.076}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "optimizer1 = AdamW(model.parameters(), lr=2e-5)\n",
    "args_adam1 = TrainingArguments(\n",
    "    \"bert-finetuned-adam1\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer_adam1 = Trainer(\n",
    "    model=model,\n",
    "    args=args_adam1,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer1, None)\n",
    ")\n",
    "\n",
    "trainer_adam1.train()\n",
    "test_pred_adam1 = trainer_adam1.predict(test_dataset=tokenized_datasets[\"test\"])\n",
    "test_pred_adam1.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26fc094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'creative-work': {'B-label': 0.0,\n",
      "                          'I-label': 0.01015228426395939,\n",
      "                          'entity': 0.0},\n",
      "        'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'location': {'B-label': 0.04743083003952569,\n",
      "                     'I-label': 0.0,\n",
      "                     'entity': 0.0},\n",
      "        'person': {'B-label': 0.011782032400589101,\n",
      "                   'I-label': 0.0,\n",
      "                   'entity': 0.0},\n",
      "        'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}},\n",
      " 'macro_f1': 0.0,\n",
      " 'micro_f1': 0.0,\n",
      " 'precision': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'creative-work': {'B-label': 0.0,\n",
      "                                 'I-label': 0.014705882352941176,\n",
      "                                 'entity': 0.0},\n",
      "               'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'location': {'B-label': 0.05825242718446602,\n",
      "                            'I-label': 0.0,\n",
      "                            'entity': 0.0},\n",
      "               'person': {'B-label': 0.016, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}},\n",
      " 'recall': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'creative-work': {'B-label': 0.0,\n",
      "                              'I-label': 0.007751937984496124,\n",
      "                              'entity': 0.0},\n",
      "            'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'location': {'B-label': 0.04, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'person': {'B-label': 0.009324009324009324,\n",
      "                       'I-label': 0.0,\n",
      "                       'entity': 0.0},\n",
      "            'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "macro_micro_adam1 = evaluate_token_classification(predictions=test_pred_adam1.predictions, \\\n",
    "                                                  labels=test_pred_adam1.label_ids, \\\n",
    "                                                  entity_types=entity_types)\n",
    "pprint(macro_micro_adam1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b0e6e",
   "metadata": {},
   "source": [
    "We directly observe an improvement in precision and recall.\n",
    "\n",
    "We continue by manually specifying a larger batch size. While this will speed up computation, it may also harm generalisability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "470bb272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='321' max='321' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [321/321 08:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.206411</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.107656</td>\n",
       "      <td>0.178926</td>\n",
       "      <td>0.890875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.187617</td>\n",
       "      <td>0.607229</td>\n",
       "      <td>0.301435</td>\n",
       "      <td>0.402878</td>\n",
       "      <td>0.909874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.178684</td>\n",
       "      <td>0.550909</td>\n",
       "      <td>0.362440</td>\n",
       "      <td>0.437229</td>\n",
       "      <td>0.916457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arsen/miniconda3/envs/text_min/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.21888786554336548,\n",
       " 'test_precision': 0.4740882917466411,\n",
       " 'test_recall': 0.2289156626506024,\n",
       " 'test_f1': 0.30874999999999997,\n",
       " 'test_accuracy': 0.9302261306532663,\n",
       " 'test_runtime': 139.8478,\n",
       " 'test_samples_per_second': 9.203,\n",
       " 'test_steps_per_second': 1.151}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "optimizer2 = AdamW(model.parameters(), lr=2e-5)\n",
    "args_adam2 = TrainingArguments(\n",
    "    \"bert-finetuned-adam2\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    ")\n",
    "\n",
    "trainer_adam2 = Trainer(\n",
    "    model=model,\n",
    "    args=args_adam2,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer2, None)\n",
    ")\n",
    "\n",
    "trainer_adam2.train()\n",
    "test_pred_adam2 = trainer_adam2.predict(test_dataset=tokenized_datasets[\"test\"])\n",
    "test_pred_adam2.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6065f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arsen/miniconda3/envs/text_min/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'location': {'B-label': 0.022988505747126433,\n",
      "                     'I-label': 0.0,\n",
      "                     'entity': 0.014598540145985401},\n",
      "        'person': {'B-label': 0.006201550387596899,\n",
      "                   'I-label': 0.00404040404040404,\n",
      "                   'entity': 0.0},\n",
      "        'product': {'B-label': 0.0,\n",
      "                    'I-label': 0.01183431952662722,\n",
      "                    'entity': 0.0}},\n",
      " 'macro_f1': 0.0024330900243309003,\n",
      " 'micro_f1': 0.36496350364963503,\n",
      " 'precision': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'location': {'B-label': 0.02702702702702703,\n",
      "                            'I-label': 0.0,\n",
      "                            'entity': 0.016129032258064516},\n",
      "               'person': {'B-label': 0.009259259259259259,\n",
      "                          'I-label': 0.006289308176100629,\n",
      "                          'entity': 0.0},\n",
      "               'product': {'B-label': 0.0,\n",
      "                           'I-label': 0.020833333333333332,\n",
      "                           'entity': 0.0}},\n",
      " 'recall': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'location': {'B-label': 0.02,\n",
      "                         'I-label': 0.0,\n",
      "                         'entity': 0.013333333333333334},\n",
      "            'person': {'B-label': 0.004662004662004662,\n",
      "                       'I-label': 0.002976190476190476,\n",
      "                       'entity': 0.0},\n",
      "            'product': {'B-label': 0.0,\n",
      "                        'I-label': 0.008264462809917356,\n",
      "                        'entity': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "macro_micro_adam2 = evaluate_token_classification(predictions=test_pred_adam2.predictions, \\\n",
    "                                                  labels=test_pred_adam2.label_ids, \\\n",
    "                                                  entity_types=entity_types)\n",
    "pprint(macro_micro_adam2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c528b",
   "metadata": {},
   "source": [
    "Indeed, the model took less time to run 3 epochs, however suffered in performance. Particularly recall and thus F1 were harmed.\n",
    "\n",
    "Next, we increase the learning rate. This may also have a positive impact on computation time, while also acting as regularisation. Perhaps, the impact will not be as dire as with batch computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d51bd73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1275' max='1275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1275/1275 14:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.162601</td>\n",
       "      <td>0.522763</td>\n",
       "      <td>0.398325</td>\n",
       "      <td>0.452138</td>\n",
       "      <td>0.917527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.213299</td>\n",
       "      <td>0.616906</td>\n",
       "      <td>0.410287</td>\n",
       "      <td>0.492816</td>\n",
       "      <td>0.918170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.212423</td>\n",
       "      <td>0.562315</td>\n",
       "      <td>0.453349</td>\n",
       "      <td>0.501987</td>\n",
       "      <td>0.922933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.25418907403945923,\n",
       " 'test_precision': 0.45779685264663805,\n",
       " 'test_recall': 0.2965708989805375,\n",
       " 'test_f1': 0.3599550056242969,\n",
       " 'test_accuracy': 0.9331155778894472,\n",
       " 'test_runtime': 89.2379,\n",
       " 'test_samples_per_second': 14.422,\n",
       " 'test_steps_per_second': 1.804}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "optimizer3 = AdamW(model.parameters(), lr=9e-5)\n",
    "args_adam3 = TrainingArguments(\n",
    "    \"bert-finetuned-adam3\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer_adam3 = Trainer(\n",
    "    model=model,\n",
    "    args=args_adam3,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer3, None)\n",
    ")\n",
    "\n",
    "trainer_adam3.train()\n",
    "test_pred_adam3 = trainer_adam3.predict(test_dataset=tokenized_datasets[\"test\"])\n",
    "test_pred_adam3.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29428c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'creative-work': {'B-label': 0.0,\n",
      "                          'I-label': 0.010810810810810811,\n",
      "                          'entity': 0.0},\n",
      "        'group': {'B-label': 0.008583690987124463,\n",
      "                  'I-label': 0.0,\n",
      "                  'entity': 0.0},\n",
      "        'location': {'B-label': 0.03187250996015937,\n",
      "                     'I-label': 0.0,\n",
      "                     'entity': 0.0},\n",
      "        'person': {'B-label': 0.015128593040847202,\n",
      "                   'I-label': 0.004048582995951417,\n",
      "                   'entity': 0.005822416302765647},\n",
      "        'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}},\n",
      " 'macro_f1': 0.0009704027171276078,\n",
      " 'micro_f1': 0.41630276564774377,\n",
      " 'precision': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'creative-work': {'B-label': 0.0,\n",
      "                                 'I-label': 0.017857142857142856,\n",
      "                                 'entity': 0.0},\n",
      "               'group': {'B-label': 0.014705882352941176,\n",
      "                         'I-label': 0.0,\n",
      "                         'entity': 0.0},\n",
      "               'location': {'B-label': 0.039603960396039604,\n",
      "                            'I-label': 0.0,\n",
      "                            'entity': 0.0},\n",
      "               'person': {'B-label': 0.021551724137931036,\n",
      "                          'I-label': 0.006329113924050633,\n",
      "                          'entity': 0.007751937984496124},\n",
      "               'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}},\n",
      " 'recall': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'creative-work': {'B-label': 0.0,\n",
      "                              'I-label': 0.007751937984496124,\n",
      "                              'entity': 0.0},\n",
      "            'group': {'B-label': 0.006060606060606061,\n",
      "                      'I-label': 0.0,\n",
      "                      'entity': 0.0},\n",
      "            'location': {'B-label': 0.02666666666666667,\n",
      "                         'I-label': 0.0,\n",
      "                         'entity': 0.0},\n",
      "            'person': {'B-label': 0.011655011655011656,\n",
      "                       'I-label': 0.002976190476190476,\n",
      "                       'entity': 0.004662004662004662},\n",
      "            'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "macro_micro_adam3 = evaluate_token_classification(predictions=test_pred_adam3.predictions, \\\n",
    "                                                  labels=test_pred_adam3.label_ids, \\\n",
    "                                                  entity_types=entity_types)\n",
    "pprint(macro_micro_adam3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc5c77",
   "metadata": {},
   "source": [
    "The model actually has better precision than the baseline. However, recall still underperforms, leading to an overall lower F1. It appears that the true positives of the test data do not resemble the training data too well, making the recall worse.\n",
    "We will try the same learning rate, including the increased batch size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae9b2a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='321' max='321' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [321/321 08:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.207578</td>\n",
       "      <td>0.457198</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>0.348148</td>\n",
       "      <td>0.903345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.180311</td>\n",
       "      <td>0.599641</td>\n",
       "      <td>0.399522</td>\n",
       "      <td>0.479541</td>\n",
       "      <td>0.916350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.177670</td>\n",
       "      <td>0.528190</td>\n",
       "      <td>0.425837</td>\n",
       "      <td>0.471523</td>\n",
       "      <td>0.920150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arsen/miniconda3/envs/text_min/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.2290385514497757,\n",
       " 'test_precision': 0.4583333333333333,\n",
       " 'test_recall': 0.29564411492122333,\n",
       " 'test_f1': 0.3594366197183098,\n",
       " 'test_accuracy': 0.9332663316582914,\n",
       " 'test_runtime': 144.5128,\n",
       " 'test_samples_per_second': 8.906,\n",
       " 'test_steps_per_second': 1.114}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "optimizer4 = AdamW(model.parameters(), lr=9e-5)\n",
    "args_adam4 = TrainingArguments(\n",
    "    \"bert-finetuned-adam4\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    ")\n",
    "\n",
    "trainer_adam4 = Trainer(\n",
    "    model=model,\n",
    "    args=args_adam4,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer4, None)\n",
    ")\n",
    "\n",
    "trainer_adam4.train()\n",
    "test_pred_adam4 = trainer_adam4.predict(test_dataset=tokenized_datasets[\"test\"])\n",
    "test_pred_adam4.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d29c87eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': {'corporation': {'B-label': 0.014492753623188406,\n",
      "                        'I-label': 0.0,\n",
      "                        'entity': 0.0},\n",
      "        'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'group': {'B-label': 0.009389671361502348,\n",
      "                  'I-label': 0.0,\n",
      "                  'entity': 0.0},\n",
      "        'location': {'B-label': 0.01556420233463035,\n",
      "                     'I-label': 0.0,\n",
      "                     'entity': 0.0},\n",
      "        'person': {'B-label': 0.008771929824561403,\n",
      "                   'I-label': 0.00404040404040404,\n",
      "                   'entity': 0.0028653295128939827},\n",
      "        'product': {'B-label': 0.0,\n",
      "                    'I-label': 0.01098901098901099,\n",
      "                    'entity': 0.0}},\n",
      " 'macro_f1': 0.0004775549188156638,\n",
      " 'micro_f1': 0.20487106017191978,\n",
      " 'precision': {'corporation': {'B-label': 0.013888888888888888,\n",
      "                               'I-label': 0.0,\n",
      "                               'entity': 0.0},\n",
      "               'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'group': {'B-label': 0.020833333333333332,\n",
      "                         'I-label': 0.0,\n",
      "                         'entity': 0.0},\n",
      "               'location': {'B-label': 0.018691588785046728,\n",
      "                            'I-label': 0.0,\n",
      "                            'entity': 0.0},\n",
      "               'person': {'B-label': 0.011764705882352941,\n",
      "                          'I-label': 0.006289308176100629,\n",
      "                          'entity': 0.0037174721189591076},\n",
      "               'product': {'B-label': 0.0,\n",
      "                           'I-label': 0.01639344262295082,\n",
      "                           'entity': 0.0}},\n",
      " 'recall': {'corporation': {'B-label': 0.015151515151515152,\n",
      "                            'I-label': 0.0,\n",
      "                            'entity': 0.0},\n",
      "            'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'group': {'B-label': 0.006060606060606061,\n",
      "                      'I-label': 0.0,\n",
      "                      'entity': 0.0},\n",
      "            'location': {'B-label': 0.013333333333333334,\n",
      "                         'I-label': 0.0,\n",
      "                         'entity': 0.0},\n",
      "            'person': {'B-label': 0.006993006993006993,\n",
      "                       'I-label': 0.002976190476190476,\n",
      "                       'entity': 0.002331002331002331},\n",
      "            'product': {'B-label': 0.0,\n",
      "                        'I-label': 0.008264462809917356,\n",
      "                        'entity': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "macro_micro_adam4 = evaluate_token_classification(predictions=test_pred_adam4.predictions, \\\n",
    "                                                  labels=test_pred_adam4.label_ids, \\\n",
    "                                                  entity_types=entity_types)\n",
    "pprint(macro_micro_adam4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b276cdc4",
   "metadata": {},
   "source": [
    "As it has proven challenging to improve the model, we will also try a lower learning rate than at baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f36d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1275' max='1275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1275/1275 13:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.179638</td>\n",
       "      <td>0.536398</td>\n",
       "      <td>0.334928</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>0.910142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.184050</td>\n",
       "      <td>0.593066</td>\n",
       "      <td>0.388756</td>\n",
       "      <td>0.469653</td>\n",
       "      <td>0.918170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.173764</td>\n",
       "      <td>0.578295</td>\n",
       "      <td>0.446172</td>\n",
       "      <td>0.503714</td>\n",
       "      <td>0.922023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.2258116602897644,\n",
       " 'test_precision': 0.4864864864864865,\n",
       " 'test_recall': 0.283595922150139,\n",
       " 'test_f1': 0.3583138173302108,\n",
       " 'test_accuracy': 0.9335175879396985,\n",
       " 'test_runtime': 88.1595,\n",
       " 'test_samples_per_second': 14.599,\n",
       " 'test_steps_per_second': 1.826}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "optimizer5 = AdamW(model.parameters(), lr=1e-5)\n",
    "args_adam5 = TrainingArguments(\n",
    "    \"bert-finetuned-adam5\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer_adam5 = Trainer(\n",
    "    model=model,\n",
    "    args=args_adam5,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer5, None)\n",
    ")\n",
    "\n",
    "trainer_adam5.train()\n",
    "test_pred_adam5 = trainer_adam5.predict(test_dataset=tokenized_datasets[\"test\"])\n",
    "test_pred_adam5.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f9aed5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'location': {'B-label': 0.030303030303030304,\n",
      "                     'I-label': 0.0,\n",
      "                     'entity': 0.0},\n",
      "        'person': {'B-label': 0.00904977375565611,\n",
      "                   'I-label': 0.0,\n",
      "                   'entity': 0.0},\n",
      "        'product': {'B-label': 0.0, 'I-label': 0.03125, 'entity': 0.0}},\n",
      " 'macro_f1': 0.0,\n",
      " 'micro_f1': 0.0,\n",
      " 'precision': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'location': {'B-label': 0.03508771929824561,\n",
      "                            'I-label': 0.0,\n",
      "                            'entity': 0.0},\n",
      "               'person': {'B-label': 0.01282051282051282,\n",
      "                          'I-label': 0.0,\n",
      "                          'entity': 0.0},\n",
      "               'product': {'B-label': 0.0,\n",
      "                           'I-label': 0.04225352112676056,\n",
      "                           'entity': 0.0}},\n",
      " 'recall': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'location': {'B-label': 0.02666666666666667,\n",
      "                         'I-label': 0.0,\n",
      "                         'entity': 0.0},\n",
      "            'person': {'B-label': 0.006993006993006993,\n",
      "                       'I-label': 0.0,\n",
      "                       'entity': 0.0},\n",
      "            'product': {'B-label': 0.0,\n",
      "                        'I-label': 0.024793388429752067,\n",
      "                        'entity': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "macro_micro_adam5 = evaluate_token_classification(predictions=test_pred_adam5.predictions, \\\n",
    "                                                  labels=test_pred_adam5.label_ids, \\\n",
    "                                                  entity_types=entity_types)\n",
    "pprint(macro_micro_adam5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0f4a4",
   "metadata": {},
   "source": [
    "The decrease in model performance is negligible.\n",
    "Again, we also try to increase the batch size to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fdd7781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='321' max='321' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [321/321 09:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.056220</td>\n",
       "      <td>0.098843</td>\n",
       "      <td>0.888360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212453</td>\n",
       "      <td>0.506977</td>\n",
       "      <td>0.130383</td>\n",
       "      <td>0.207422</td>\n",
       "      <td>0.892695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arsen/miniconda3/envs/text_min/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arsen/miniconda3/envs/text_min/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.23187460005283356,\n",
       " 'test_precision': 0.5045454545454545,\n",
       " 'test_recall': 0.10287303058387395,\n",
       " 'test_f1': 0.17090069284064663,\n",
       " 'test_accuracy': 0.9205778894472362,\n",
       " 'test_runtime': 143.5492,\n",
       " 'test_samples_per_second': 8.966,\n",
       " 'test_steps_per_second': 1.122}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "optimizer6 = AdamW(model.parameters(), lr=1e-5)\n",
    "args_adam6 = TrainingArguments(\n",
    "    \"bert-finetuned-adam6\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    ")\n",
    "\n",
    "trainer_adam6 = Trainer(\n",
    "    model=model,\n",
    "    args=args_adam6,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer6, None)\n",
    ")\n",
    "\n",
    "trainer_adam6.train()\n",
    "test_pred_adam6 = trainer_adam6.predict(test_dataset=tokenized_datasets[\"test\"])\n",
    "test_pred_adam6.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7b05098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "        'location': {'B-label': 0.0,\n",
      "                     'I-label': 0.017543859649122806,\n",
      "                     'entity': 0.0},\n",
      "        'person': {'B-label': 0.0,\n",
      "                   'I-label': 0.019569471624266144,\n",
      "                   'entity': 0.0},\n",
      "        'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}},\n",
      " 'macro_f1': 0.0,\n",
      " 'micro_f1': 0.0,\n",
      " 'precision': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "               'location': {'B-label': 0.0,\n",
      "                            'I-label': 0.05263157894736842,\n",
      "                            'entity': 0.0},\n",
      "               'person': {'B-label': 0.0,\n",
      "                          'I-label': 0.02857142857142857,\n",
      "                          'entity': 0.0},\n",
      "               'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}},\n",
      " 'recall': {'corporation': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'creative-work': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'group': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0},\n",
      "            'location': {'B-label': 0.0,\n",
      "                         'I-label': 0.010526315789473684,\n",
      "                         'entity': 0.0},\n",
      "            'person': {'B-label': 0.0,\n",
      "                       'I-label': 0.01488095238095238,\n",
      "                       'entity': 0.0},\n",
      "            'product': {'B-label': 0.0, 'I-label': 0.0, 'entity': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "macro_micro_adam6 = evaluate_token_classification(predictions=test_pred_adam6.predictions, \\\n",
    "                                                  labels=test_pred_adam6.label_ids, \\\n",
    "                                                  entity_types=entity_types)\n",
    "pprint(macro_micro_adam6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bfba00",
   "metadata": {},
   "source": [
    "This model struggles a lot to correctly identify true positives from false negatives, leading to a terrible Recall and F1 score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_min",
   "language": "python",
   "name": "text_min"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
