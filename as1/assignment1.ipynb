{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfc223e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c07a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d0136",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd7fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train')\n",
    "twenty_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcd0bd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 7532)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train['data']), len(twenty_test['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01e0816b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf789a8",
   "metadata": {},
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb85225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_test_counts = count_vect.transform(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "349b75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bae16023",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(X_train_counts)\n",
    "X_train_tfidf = tf_transformer.transform(X_train_counts)\n",
    "X_test_tfidf = tf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ea976",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa71bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = twenty_train.target, twenty_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e423b9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  5,  0, ...,  9,  6, 15])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44d206",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "061d6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf_counts = MultinomialNB().fit(X_train_counts, y_train)\n",
    "nb_clf_tf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "nb_clf_tfidf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "987e6541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.79      0.77      0.78       319\n",
      "           comp.graphics       0.67      0.74      0.70       389\n",
      " comp.os.ms-windows.misc       0.20      0.00      0.01       394\n",
      "comp.sys.ibm.pc.hardware       0.56      0.77      0.65       392\n",
      "   comp.sys.mac.hardware       0.84      0.75      0.79       385\n",
      "          comp.windows.x       0.65      0.84      0.73       395\n",
      "            misc.forsale       0.93      0.65      0.77       390\n",
      "               rec.autos       0.87      0.91      0.89       396\n",
      "         rec.motorcycles       0.96      0.92      0.94       398\n",
      "      rec.sport.baseball       0.96      0.87      0.91       397\n",
      "        rec.sport.hockey       0.93      0.96      0.95       399\n",
      "               sci.crypt       0.67      0.95      0.78       396\n",
      "         sci.electronics       0.79      0.66      0.72       393\n",
      "                 sci.med       0.87      0.82      0.85       396\n",
      "               sci.space       0.83      0.89      0.86       394\n",
      "  soc.religion.christian       0.70      0.96      0.81       398\n",
      "      talk.politics.guns       0.69      0.91      0.79       364\n",
      "   talk.politics.mideast       0.85      0.94      0.89       376\n",
      "      talk.politics.misc       0.58      0.63      0.60       310\n",
      "      talk.religion.misc       0.89      0.33      0.49       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.76      0.76      0.75      7532\n",
      "            weighted avg       0.76      0.77      0.75      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_nb_counts = nb_clf_counts.predict(X_test_counts)\n",
    "print(classification_report(y_test, y_test_nb_counts, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f32d3315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.85      0.24      0.37       319\n",
      "           comp.graphics       0.71      0.60      0.65       389\n",
      " comp.os.ms-windows.misc       0.79      0.65      0.71       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.75      0.69       392\n",
      "   comp.sys.mac.hardware       0.86      0.68      0.76       385\n",
      "          comp.windows.x       0.88      0.68      0.77       395\n",
      "            misc.forsale       0.90      0.72      0.80       390\n",
      "               rec.autos       0.71      0.92      0.80       396\n",
      "         rec.motorcycles       0.84      0.91      0.87       398\n",
      "      rec.sport.baseball       0.86      0.85      0.86       397\n",
      "        rec.sport.hockey       0.90      0.93      0.91       399\n",
      "               sci.crypt       0.52      0.96      0.67       396\n",
      "         sci.electronics       0.78      0.52      0.63       393\n",
      "                 sci.med       0.82      0.76      0.79       396\n",
      "               sci.space       0.83      0.81      0.82       394\n",
      "  soc.religion.christian       0.34      0.98      0.51       398\n",
      "      talk.politics.guns       0.66      0.80      0.73       364\n",
      "   talk.politics.mideast       0.96      0.72      0.82       376\n",
      "      talk.politics.misc       1.00      0.17      0.29       310\n",
      "      talk.religion.misc       1.00      0.01      0.02       251\n",
      "\n",
      "                accuracy                           0.71      7532\n",
      "               macro avg       0.79      0.68      0.67      7532\n",
      "            weighted avg       0.79      0.71      0.69      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_nb_tf = nb_clf_tf.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_test_nb_tf, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1761d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.85      0.24      0.37       319\n",
      "           comp.graphics       0.71      0.60      0.65       389\n",
      " comp.os.ms-windows.misc       0.79      0.65      0.71       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.75      0.69       392\n",
      "   comp.sys.mac.hardware       0.86      0.68      0.76       385\n",
      "          comp.windows.x       0.88      0.68      0.77       395\n",
      "            misc.forsale       0.90      0.72      0.80       390\n",
      "               rec.autos       0.71      0.92      0.80       396\n",
      "         rec.motorcycles       0.84      0.91      0.87       398\n",
      "      rec.sport.baseball       0.86      0.85      0.86       397\n",
      "        rec.sport.hockey       0.90      0.93      0.91       399\n",
      "               sci.crypt       0.52      0.96      0.67       396\n",
      "         sci.electronics       0.78      0.52      0.63       393\n",
      "                 sci.med       0.82      0.76      0.79       396\n",
      "               sci.space       0.83      0.81      0.82       394\n",
      "  soc.religion.christian       0.34      0.98      0.51       398\n",
      "      talk.politics.guns       0.66      0.80      0.73       364\n",
      "   talk.politics.mideast       0.96      0.72      0.82       376\n",
      "      talk.politics.misc       1.00      0.17      0.29       310\n",
      "      talk.religion.misc       1.00      0.01      0.02       251\n",
      "\n",
      "                accuracy                           0.71      7532\n",
      "               macro avg       0.79      0.68      0.67      7532\n",
      "            weighted avg       0.79      0.71      0.69      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_nb_tfidf = nb_clf_tf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_test_nb_tfidf, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9e2f2",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f445d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf_counts = DecisionTreeClassifier().fit(X_train_counts, y_train)\n",
    "dt_clf_tf = DecisionTreeClassifier().fit(X_train_tf, y_train)\n",
    "dt_clf_tfidf = DecisionTreeClassifier().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d810165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.47      0.46      0.47       319\n",
      "           comp.graphics       0.47      0.46      0.46       389\n",
      " comp.os.ms-windows.misc       0.56      0.59      0.57       394\n",
      "comp.sys.ibm.pc.hardware       0.40      0.45      0.42       392\n",
      "   comp.sys.mac.hardware       0.50      0.57      0.53       385\n",
      "          comp.windows.x       0.51      0.47      0.49       395\n",
      "            misc.forsale       0.69      0.72      0.70       390\n",
      "               rec.autos       0.57      0.63      0.60       396\n",
      "         rec.motorcycles       0.72      0.77      0.74       398\n",
      "      rec.sport.baseball       0.59      0.61      0.60       397\n",
      "        rec.sport.hockey       0.72      0.72      0.72       399\n",
      "               sci.crypt       0.83      0.71      0.76       396\n",
      "         sci.electronics       0.36      0.32      0.34       393\n",
      "                 sci.med       0.48      0.42      0.45       396\n",
      "               sci.space       0.67      0.67      0.67       394\n",
      "  soc.religion.christian       0.76      0.71      0.74       398\n",
      "      talk.politics.guns       0.55      0.67      0.60       364\n",
      "   talk.politics.mideast       0.81      0.62      0.70       376\n",
      "      talk.politics.misc       0.39      0.39      0.39       310\n",
      "      talk.religion.misc       0.33      0.32      0.33       251\n",
      "\n",
      "                accuracy                           0.57      7532\n",
      "               macro avg       0.57      0.56      0.56      7532\n",
      "            weighted avg       0.58      0.57      0.57      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_dt_counts = dt_clf_counts.predict(X_test_counts)\n",
    "print(classification_report(y_test, y_test_dt_counts, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0d48b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.51      0.46      0.48       319\n",
      "           comp.graphics       0.39      0.43      0.41       389\n",
      " comp.os.ms-windows.misc       0.54      0.58      0.56       394\n",
      "comp.sys.ibm.pc.hardware       0.41      0.42      0.41       392\n",
      "   comp.sys.mac.hardware       0.49      0.56      0.52       385\n",
      "          comp.windows.x       0.57      0.50      0.53       395\n",
      "            misc.forsale       0.70      0.71      0.70       390\n",
      "               rec.autos       0.56      0.53      0.55       396\n",
      "         rec.motorcycles       0.71      0.80      0.75       398\n",
      "      rec.sport.baseball       0.57      0.58      0.57       397\n",
      "        rec.sport.hockey       0.75      0.72      0.73       399\n",
      "               sci.crypt       0.77      0.70      0.73       396\n",
      "         sci.electronics       0.28      0.29      0.28       393\n",
      "                 sci.med       0.50      0.45      0.47       396\n",
      "               sci.space       0.65      0.61      0.63       394\n",
      "  soc.religion.christian       0.70      0.68      0.69       398\n",
      "      talk.politics.guns       0.52      0.64      0.57       364\n",
      "   talk.politics.mideast       0.78      0.60      0.68       376\n",
      "      talk.politics.misc       0.38      0.38      0.38       310\n",
      "      talk.religion.misc       0.35      0.37      0.36       251\n",
      "\n",
      "                accuracy                           0.56      7532\n",
      "               macro avg       0.56      0.55      0.55      7532\n",
      "            weighted avg       0.56      0.56      0.56      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_dt_tf = dt_clf_tf.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_test_dt_tf, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf7bedf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.51      0.46      0.48       319\n",
      "           comp.graphics       0.39      0.43      0.41       389\n",
      " comp.os.ms-windows.misc       0.54      0.58      0.56       394\n",
      "comp.sys.ibm.pc.hardware       0.41      0.42      0.41       392\n",
      "   comp.sys.mac.hardware       0.49      0.56      0.52       385\n",
      "          comp.windows.x       0.57      0.50      0.53       395\n",
      "            misc.forsale       0.70      0.71      0.70       390\n",
      "               rec.autos       0.56      0.53      0.55       396\n",
      "         rec.motorcycles       0.71      0.80      0.75       398\n",
      "      rec.sport.baseball       0.57      0.58      0.57       397\n",
      "        rec.sport.hockey       0.75      0.72      0.73       399\n",
      "               sci.crypt       0.77      0.70      0.73       396\n",
      "         sci.electronics       0.28      0.29      0.28       393\n",
      "                 sci.med       0.50      0.45      0.47       396\n",
      "               sci.space       0.65      0.61      0.63       394\n",
      "  soc.religion.christian       0.70      0.68      0.69       398\n",
      "      talk.politics.guns       0.52      0.64      0.57       364\n",
      "   talk.politics.mideast       0.78      0.60      0.68       376\n",
      "      talk.politics.misc       0.38      0.38      0.38       310\n",
      "      talk.religion.misc       0.35      0.37      0.36       251\n",
      "\n",
      "                accuracy                           0.56      7532\n",
      "               macro avg       0.56      0.55      0.55      7532\n",
      "            weighted avg       0.56      0.56      0.56      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_dt_tfidf = dt_clf_tf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_test_dt_tfidf, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023f0b5",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b6e389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_counts = SVC().fit(X_train_counts, y_train)\n",
    "svm_clf_tf = SVC().fit(X_train_tf, y_train)\n",
    "svm_clf_tfidf = SVC().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f248bba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.33      0.02      0.03       319\n",
      "           comp.graphics       0.05      0.17      0.08       389\n",
      " comp.os.ms-windows.misc       0.33      0.02      0.03       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.03      0.06       392\n",
      "   comp.sys.mac.hardware       1.00      0.00      0.01       385\n",
      "          comp.windows.x       0.64      0.05      0.09       395\n",
      "            misc.forsale       0.09      0.94      0.17       390\n",
      "               rec.autos       0.39      0.10      0.15       396\n",
      "         rec.motorcycles       0.10      0.25      0.15       398\n",
      "      rec.sport.baseball       0.52      0.11      0.18       397\n",
      "        rec.sport.hockey       0.58      0.08      0.14       399\n",
      "               sci.crypt       0.41      0.16      0.23       396\n",
      "         sci.electronics       0.21      0.02      0.03       393\n",
      "                 sci.med       0.28      0.10      0.15       396\n",
      "               sci.space       0.56      0.05      0.09       394\n",
      "  soc.religion.christian       0.42      0.37      0.39       398\n",
      "      talk.politics.guns       0.33      0.16      0.21       364\n",
      "   talk.politics.mideast       0.74      0.26      0.38       376\n",
      "      talk.politics.misc       0.73      0.05      0.10       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "                accuracy                           0.15      7532\n",
      "               macro avg       0.42      0.15      0.13      7532\n",
      "            weighted avg       0.42      0.15      0.14      7532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arsen/miniconda3/envs/text_min/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arsen/miniconda3/envs/text_min/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arsen/miniconda3/envs/text_min/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_test_svm_counts = svm_clf_counts.predict(X_test_counts)\n",
    "print(classification_report(y_test, y_test_svm_counts, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be7a002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.67      0.63      0.65       319\n",
      "           comp.graphics       0.55      0.76      0.64       389\n",
      " comp.os.ms-windows.misc       0.73      0.62      0.67       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.66      0.66       392\n",
      "   comp.sys.mac.hardware       0.75      0.75      0.75       385\n",
      "          comp.windows.x       0.76      0.68      0.72       395\n",
      "            misc.forsale       0.74      0.89      0.81       390\n",
      "               rec.autos       0.78      0.79      0.79       396\n",
      "         rec.motorcycles       0.86      0.87      0.86       398\n",
      "      rec.sport.baseball       0.74      0.83      0.78       397\n",
      "        rec.sport.hockey       0.93      0.86      0.89       399\n",
      "               sci.crypt       0.94      0.80      0.86       396\n",
      "         sci.electronics       0.59      0.72      0.65       393\n",
      "                 sci.med       0.69      0.63      0.66       396\n",
      "               sci.space       0.92      0.83      0.87       394\n",
      "  soc.religion.christian       0.76      0.91      0.83       398\n",
      "      talk.politics.guns       0.69      0.81      0.74       364\n",
      "   talk.politics.mideast       0.94      0.74      0.83       376\n",
      "      talk.politics.misc       0.60      0.51      0.55       310\n",
      "      talk.religion.misc       0.67      0.41      0.50       251\n",
      "\n",
      "                accuracy                           0.74      7532\n",
      "               macro avg       0.75      0.74      0.74      7532\n",
      "            weighted avg       0.75      0.74      0.74      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_svm_tf = svm_clf_tf.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_test_svm_tf, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1228ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.67      0.63      0.65       319\n",
      "           comp.graphics       0.55      0.76      0.64       389\n",
      " comp.os.ms-windows.misc       0.73      0.62      0.67       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.66      0.66       392\n",
      "   comp.sys.mac.hardware       0.75      0.75      0.75       385\n",
      "          comp.windows.x       0.76      0.68      0.72       395\n",
      "            misc.forsale       0.74      0.89      0.81       390\n",
      "               rec.autos       0.78      0.79      0.79       396\n",
      "         rec.motorcycles       0.86      0.87      0.86       398\n",
      "      rec.sport.baseball       0.74      0.83      0.78       397\n",
      "        rec.sport.hockey       0.93      0.86      0.89       399\n",
      "               sci.crypt       0.94      0.80      0.86       396\n",
      "         sci.electronics       0.59      0.72      0.65       393\n",
      "                 sci.med       0.69      0.63      0.66       396\n",
      "               sci.space       0.92      0.83      0.87       394\n",
      "  soc.religion.christian       0.76      0.91      0.83       398\n",
      "      talk.politics.guns       0.69      0.81      0.74       364\n",
      "   talk.politics.mideast       0.94      0.74      0.83       376\n",
      "      talk.politics.misc       0.60      0.51      0.55       310\n",
      "      talk.religion.misc       0.67      0.41      0.50       251\n",
      "\n",
      "                accuracy                           0.74      7532\n",
      "               macro avg       0.75      0.74      0.74      7532\n",
      "            weighted avg       0.75      0.74      0.74      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_svm_tfidf = svm_clf_tf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_test_svm_tfidf, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d891aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_min",
   "language": "python",
   "name": "text_min"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
